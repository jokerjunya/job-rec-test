#!/usr/bin/env python3
"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•ãƒ­ã‚°ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®Recommendedåˆ—ã‹ã‚‰ã€ã‚ˆã‚Šç¾å®Ÿçš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’ç”Ÿæˆ
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict
import json


class UserInteractionLogGenerator:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, csv_path: str):
        """
        åˆæœŸåŒ–
        
        Args:
            csv_path: Job Recommendation Datasetã®ãƒ‘ã‚¹
        """
        print(f"ğŸ“– Loading dataset from {csv_path}...")
        self.df = pd.read_csv(csv_path)
        print(f"   âœ… Loaded {len(self.df):,} rows")
    
    def generate_realistic_logs(
        self,
        views_per_user_min: int = 5,
        views_per_user_max: int = 20,
        like_probability_multiplier: float = 0.9
    ) -> pd.DataFrame:
        """
        ç¾å®Ÿçš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’ç”Ÿæˆ
        
        Args:
            views_per_user_min: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ1æ—¥ã‚ãŸã‚Šè¦‹ã‚‹æ±‚äººã®æœ€å°æ•°
            views_per_user_max: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ1æ—¥ã‚ãŸã‚Šè¦‹ã‚‹æ±‚äººã®æœ€å¤§æ•°
            like_probability_multiplier: likeç¢ºç‡ã®èª¿æ•´ä¿‚æ•°
        
        Returns:
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®DataFrame
        """
        print("\nğŸ”¨ Generating realistic user interaction logs...")
        
        logs = []
        unique_users = self.df['User_ID'].unique()
        
        # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã«ãƒ­ã‚°ã‚’ç”Ÿæˆ
        for idx, user_id in enumerate(unique_users):
            if (idx + 1) % 10000 == 0:
                print(f"   Processing user {idx + 1}/{len(unique_users)}...")
            
            user_data = self.df[self.df['User_ID'] == user_id].copy()
            
            # Match_ScoreãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒãƒƒãƒåº¦ã®é«˜ã„æ±‚äººã‹ã‚‰è¦‹ã‚‹ï¼‰
            user_data_sorted = user_data.sort_values('Match_Score', ascending=False)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ1æ—¥ã‚ãŸã‚Šè¦‹ã‚‹æ±‚äººæ•°ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰
            num_views = np.random.randint(views_per_user_min, views_per_user_max + 1)
            
            # ä¸Šä½Nä»¶ã‚’è¦‹ã‚‹
            viewed_jobs = user_data_sorted.head(num_views)
            
            # è¦‹ãŸé †ç•ªã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆï¼ˆéå»30æ—¥é–“ï¼‰
            base_date = datetime.now()
            
            for view_idx, (_, row) in enumerate(viewed_jobs.iterrows()):
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: éå»30æ—¥é–“ã®ãƒ©ãƒ³ãƒ€ãƒ ãªæ™‚åˆ»
                days_ago = np.random.randint(0, 30)
                hours_ago = np.random.randint(0, 24)
                minutes_ago = np.random.randint(0, 60)
                
                timestamp = base_date - timedelta(
                    days=days_ago,
                    hours=hours_ago,
                    minutes=minutes_ago
                )
                
                # Match_Scoreã«åŸºã¥ã„ã¦ã€ç¢ºç‡çš„ã«like/dislikeã‚’æ±ºå®š
                # Match_ScoreãŒé«˜ã„ã»ã©likeã—ã‚„ã™ã„
                # ãŸã ã—ã€Recommended=1ã®å ´åˆã¯ç¢ºå®Ÿã«like
                if row['Recommended'] == 1:
                    action = 'like'
                    confidence = 1.0
                else:
                    # Match_Scoreã«åŸºã¥ãç¢ºç‡
                    like_probability = row['Match_Score'] * like_probability_multiplier
                    
                    # ç¢ºç‡çš„ã«æ±ºå®š
                    action = 'like' if np.random.random() < like_probability else 'dislike'
                    confidence = like_probability
                
                # ã‚¹ãƒ¯ã‚¤ãƒ—æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰- çŸ­ã„ã»ã©dislikeã—ã‚„ã™ã„
                if action == 'like':
                    swipe_duration_ms = np.random.randint(2000, 10000)  # 2-10ç§’
                else:
                    swipe_duration_ms = np.random.randint(500, 2000)  # 0.5-2ç§’
                
                logs.append({
                    'user_id': int(user_id),
                    'job_id': int(row['Job_ID']),
                    'action': action,
                    'timestamp': timestamp.isoformat(),
                    'match_score': float(row['Match_Score']),
                    'swipe_duration_ms': int(swipe_duration_ms),
                    'confidence': float(confidence),
                    'user_skills': row['User_Skills'],
                    'job_requirements': row['Job_Requirements']
                })
        
        logs_df = pd.DataFrame(logs)
        print(f"\nâœ… Generated {len(logs_df):,} interaction logs")
        print(f"   - Likes: {(logs_df['action'] == 'like').sum():,} ({(logs_df['action'] == 'like').sum() / len(logs_df) * 100):.1f}%)")
        print(f"   - Dislikes: {(logs_df['action'] == 'dislike').sum():,} ({(logs_df['action'] == 'dislike').sum() / len(logs_df) * 100):.1f}%)")
        
        return logs_df
    
    def generate_simple_logs(self) -> pd.DataFrame:
        """
        ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ­ã‚°ç”Ÿæˆï¼ˆRecommendedåˆ—ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
        """
        print("\nğŸ”¨ Generating simple interaction logs...")
        
        logs = []
        
        for _, row in self.df.iterrows():
            # Recommended=1 â†’ like, Recommended=0 â†’ dislike
            action = 'like' if row['Recommended'] == 1 else 'dislike'
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯ç¾åœ¨æ™‚åˆ»ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
            timestamp = datetime.now()
            
            logs.append({
                'user_id': int(row['User_ID']),
                'job_id': int(row['Job_ID']),
                'action': action,
                'timestamp': timestamp.isoformat(),
                'match_score': float(row['Match_Score']),
                'user_skills': row['User_Skills'],
                'job_requirements': row['Job_Requirements']
            })
        
        logs_df = pd.DataFrame(logs)
        print(f"âœ… Generated {len(logs_df):,} interaction logs")
        
        return logs_df
    
    def save_logs(self, logs_df: pd.DataFrame, output_path: str, format: str = 'csv'):
        """
        ãƒ­ã‚°ã‚’ä¿å­˜
        
        Args:
            logs_df: ãƒ­ã‚°ã®DataFrame
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            format: ä¿å­˜å½¢å¼ ('csv', 'json', 'parquet')
        """
        print(f"\nğŸ’¾ Saving logs to {output_path}...")
        
        if format == 'csv':
            logs_df.to_csv(output_path, index=False)
        elif format == 'json':
            logs_df.to_json(output_path, orient='records', indent=2)
        elif format == 'parquet':
            logs_df.to_parquet(output_path, index=False)
        
        print(f"   âœ… Saved successfully!")
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        print(f"\nğŸ“Š Log Statistics:")
        print(f"   - Total logs: {len(logs_df):,}")
        print(f"   - Unique users: {logs_df['user_id'].nunique():,}")
        print(f"   - Unique jobs: {logs_df['job_id'].nunique():,}")
        print(f"   - Likes: {(logs_df['action'] == 'like').sum():,}")
        print(f"   - Dislikes: {(logs_df['action'] == 'dislike').sum():,}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®å¹³å‡ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ•°
        user_interactions = logs_df.groupby('user_id').size()
        print(f"   - Avg interactions per user: {user_interactions.mean():.2f}")
        print(f"   - Min interactions per user: {user_interactions.min()}")
        print(f"   - Max interactions per user: {user_interactions.max()}")


def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    print("=" * 60)
    print("ğŸš€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°ç”Ÿæˆãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    # ãƒ­ã‚°ç”Ÿæˆå™¨ã‚’åˆæœŸåŒ–
    generator = UserInteractionLogGenerator('Job Datsset.csv')
    
    # ç”Ÿæˆæ–¹æ³•ã‚’é¸æŠ
    print("\nç”Ÿæˆæ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. ç¾å®Ÿçš„ãªãƒ­ã‚°ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã€ã‚¹ãƒ¯ã‚¤ãƒ—æ™‚é–“ãªã©å«ã‚€")
    print("2. ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ­ã‚°ç”Ÿæˆ - Recommendedåˆ—ã‚’ãã®ã¾ã¾ä½¿ç”¨")
    
    choice = input("\né¸æŠ (1 or 2, default: 1): ").strip() or "1"
    
    if choice == "1":
        logs_df = generator.generate_realistic_logs(
            views_per_user_min=5,
            views_per_user_max=20,
            like_probability_multiplier=0.9
        )
        output_file = 'user_interaction_logs_realistic.csv'
    else:
        logs_df = generator.generate_simple_logs()
        output_file = 'user_interaction_logs_simple.csv'
    
    # ãƒ­ã‚°ã‚’ä¿å­˜
    generator.save_logs(logs_df, output_file, format='csv')
    
    print("\n" + "=" * 60)
    print("âœ… å®Œäº†!")
    print("=" * 60)
    print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
    print("\nğŸ’¡ ã“ã®ãƒ­ã‚°ã‚’ä½¿ã£ã¦å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã§ãã¾ã™ï¼")


if __name__ == '__main__':
    main()

